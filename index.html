<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="GIFI: A multilevel framework for evaluating gender diversity in large language models">
  <meta name="keywords" content="GIFI, Gender Fairness, LLMs, NLP">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <style>
    .publication-links .button:hover {
      background-color: #3273dc;
      border-color: #3273dc;
      color: #ffffff;
    }
    .publication-links .button:hover .icon i {
      color: #ffffff;
    }
    .icon i {
      font-family: 'Font Awesome 6 Free' !important;
      font-weight: 900 !important;
      display: inline-block !important;
    }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop has-text-centered">
      <h1 class="title is-1">Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models</h1>
      <p class="is-size-5">
        <a href="https://zhengyangshan.github.io">Zhengyang Shan</a><sup>1</sup>,
        <a href="https://www.emilyruthdiana.com">Emily Ruth Diana</a><sup>2</sup>,
        <a href="https://joezhouai.com">Jiawei Zhou</a><sup>3</sup>
      </p>
      <p class="is-size-6">
        <sup>1</sup>Boston University,
        <sup>2</sup>Carnegie Mellon University,
        <sup>3</sup>Stony Brook University
      </p>

      <div class="publication-links mt-4">
        <a href="static/gifi_paper.pdf" class="button is-dark is-rounded is-medium">
          <span class="icon"><i class="fas fa-file"></i></span>
          <span>Paper</span>
        </a>
        <a href="https://github.com/ZhengyangShan/GIFI" class="button is-dark is-rounded is-medium">
          <span class="icon"><i class="fab fa-github"></i></span>
          <span>Code</span>
        </a>
        <a href="https://huggingface.co/datasets/YOUR_USERNAME/gifi" class="button is-dark is-rounded is-medium">
          <span class="icon"><i class="fas fa-database"></i></span>
          <span>Dataset</span>
        </a>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>We present a comprehensive evaluation of gender fairness in large language models (LLMs), focusing on their ability to handle both binary and non-binary 
            genders. While previous studies primarily focus on binary gender distinctions, we introduce the Gender Inclusivity Fairness Index (GIFI), a novel and 
            comprehensive metric that quantifies the diverse gender inclusivity of LLMs. GIFI consists of a wide range of evaluations at different levels, from simply 
            probing the model with respect to provided gender pronouns to testing various aspects of model generation and cognitive behaviors under different gender 
            assumptions, revealing biases associated with varying gender identifiers. We conduct extensive evaluations with GIFI on 22 prominent open-source and 
            proprietary LLMs of varying sizes and capabilities, discovering significant variations in LLMs' gender inclusivity. Our study highlights the importance 
            of improving LLMsâ€™ inclusivity, providing a critical benchmark for future advancements in gender fairness in generative models.</p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Method Overview</h2>
    <div class="content has-text-centered">
      <img src="static/images/gifi_diagram.png" alt="GIFI method diagram" style="width:100%; max-width:800px;">
      <p>We evaluate gender fairness in LLMs through a series of progressively complex tests, organized into four stages: Pronoun Recognition, Fairness in Distribution, 
        Stereotype and Role Assignment, and Consistency in Performance</p>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Model Comparison Results</h2>
    <div class="content has-text-centered">
      <img src="static/images/model_comparison.png" alt="Model comparison" style="width:100%; max-width:800px;">
      <p>The GIFI rankings highlight models like GPT-4o, Claude 3, and DeepSeek V3 as top performers, demonstrating advanced capabilities in addressing complex tasks related to gender fairness. These models offer balanced performance across all pronoun categories. 
        Conversely, models such as Vicuna, GPT-2, and LLaMA 2 rank poorly, struggling particularly with handling neopronouns and overall gender fairness.
        
        To better understand individual model capabilities, we analyze their performance on each of the seven evaluation tasks. The radar chart offers a comparative view of all models across the seven dimensions, illustrating their diverse strengths and weaknesses. 
        
        The individual radar charts break down the performance of each model, highlighting that while some models perform well overall, they may exhibit strengths or weaknesses in specific tasks. For instance, Claude 4 excels in tasks such as sentiment neutrality and gender pronoun recognition, 
        but performs poorly in stereotypical association. GPT-4o mini demonstrates balanced performance across tasks, though with slightly lower scores in gender diversity recognition and occupational fairness. Phi-3 shows high fairness in stereotypical association and occupational fairness, 
        indicating a tendency to mitigate traditional gender roles.</p>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{shan2025gifi,
  title={Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models},
  author={Shan, Zhengyang and Diana, Emily Ruth and Zhou, Jiawei},
  booktitle={Proceedings of ACL},
  year={2025}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="static/gifi_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/ZhengyangShan/GIFI">
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>This website is adapted from the <a href="https://nerfies.github.io/">NeRFies</a> project page, licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0</a>.</p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>

